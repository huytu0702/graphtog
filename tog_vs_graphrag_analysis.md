# ToG vs GraphRAG Analysis: Integration Strategy

**Date**: 2025-02-11
**Question**: Náº¿u implement ToG cho retrieval vÃ  answer generation, cÃ³ cáº§n thá»±c hiá»‡n Ä‘áº§y Ä‘á»§ GraphRAG improvements khÃ´ng?

---

## Executive Summary

**CÃ¢u tráº£ lá»i ngáº¯n gá»n**: **KHÃ”NG, khÃ´ng cáº§n implement Ä‘áº§y Ä‘á»§ táº¥t cáº£ GraphRAG improvements náº¿u dÃ¹ng ToG.**

**LÃ½ do**: ToG vÃ  GraphRAG giáº£i quyáº¿t **cÃ¡c váº¥n Ä‘á» khÃ¡c nhau** á»Ÿ **cÃ¡c táº§ng khÃ¡c nhau** cá»§a stack. ChÃºng cÃ³ thá»ƒ **bá»• sung láº«n nhau** thay vÃ¬ thay tháº¿ hoÃ n toÃ n.

---

## So sÃ¡nh ToG vs GraphRAG

### ToG (Tree-of-Thoughts with Graph)

**Má»¥c Ä‘Ã­ch chÃ­nh**: **Reasoning layer** - CÃ¡ch LLM suy luáº­n trÃªn knowledge graph

**CÃ¡ch hoáº¡t Ä‘á»™ng**:
```
Question â†’ Extract Relations â†’ Score Entities â†’ Multi-hop Traversal â†’ Evaluate Sufficiency â†’ Generate Answer
```

**Key Features**:
1. **Structured graph reasoning** vá»›i explicit triplets (entity, relation, entity)
2. **Multi-stage prompting**:
   - Stage 1: Extract relevant relations
   - Stage 2: Score candidate entities
   - Stage 3: Evaluate sufficiency
   - Stage 4: Generate answer
3. **Backward chaining**: Tá»« question â†’ intermediate entities â†’ answer
4. **Sufficiency check**: Kiá»ƒm tra xem cÃ³ Ä‘á»§ thÃ´ng tin chÆ°a trÆ°á»›c khi tráº£ lá»i
5. **Pruning**: Filter relations vÃ  entities khÃ´ng liÃªn quan

**Äiá»ƒm máº¡nh**:
- âœ… Reasoning rÃµ rÃ ng, cÃ³ thá»ƒ trace
- âœ… Multi-hop tá»‘t (3-5 hops)
- âœ… Káº¿t há»£p graph facts + external knowledge
- âœ… Structured, interpretable

**Äiá»ƒm yáº¿u**:
- âš ï¸ YÃªu cáº§u graph structure rÃµ rÃ ng (Freebase-like)
- âš ï¸ Nhiá»u LLM calls (má»—i stage = 1 call)
- âš ï¸ Cháº­m hÆ¡n direct retrieval
- âš ï¸ KhÃ´ng xá»­ lÃ½ unstructured text tá»‘t

---

### GraphRAG (Microsoft)

**Má»¥c Ä‘Ã­ch chÃ­nh**: **Retrieval layer** - CÃ¡ch extract vÃ  retrieve context tá»« documents

**CÃ¡ch hoáº¡t Ä‘á»™ng**:
```
Documents â†’ Entity Extraction â†’ Graph Construction â†’ Community Detection â†’ Context Retrieval â†’ Answer
```

**Key Features**:
1. **Document processing**: Parse markdown/text â†’ entities + relationships
2. **Context assembly**:
   - Entity ranking (by relationship count)
   - Relationship prioritization (in-network vs out-of-network)
   - Token budget management
   - Community weighting
3. **Multi-level retrieval**:
   - Local: Entity neighborhoods
   - Community: Entity groups
   - Global: Dataset overview (Map-Reduce)
4. **Grounding**: Cite sources vá»›i [Data: Entities (id1, id2)]

**Äiá»ƒm máº¡nh**:
- âœ… Xá»­ lÃ½ unstructured documents tá»‘t
- âœ… Scalable vá»›i large datasets
- âœ… Context quality cao (ranked, prioritized)
- âœ… Token efficiency

**Äiá»ƒm yáº¿u**:
- âš ï¸ Reasoning khÃ´ng structured nhÆ° ToG
- âš ï¸ KhÃ´ng cÃ³ explicit multi-hop logic
- âš ï¸ Phá»¥ thuá»™c vÃ o LLM Ä‘á»ƒ connect entities

---

## Sá»± khÃ¡c biá»‡t cÄƒn báº£n

| Aspect | ToG | GraphRAG |
|--------|-----|----------|
| **Focus** | Reasoning process | Retrieval process |
| **Input** | Existing knowledge graph | Raw documents |
| **Graph type** | Freebase-like (typed relations) | Entity-relationship (flexible) |
| **Main strength** | Structured multi-hop reasoning | High-quality context assembly |
| **Answer method** | Chain triplets step-by-step | LLM synthesis from context |
| **Traceability** | Very high (explicit steps) | Medium (citations) |
| **Speed** | Slower (multiple stages) | Faster (single retrieval) |
| **Best for** | Complex reasoning queries | Document Q&A, summarization |

---

## Khi nÃ o nÃªn dÃ¹ng gÃ¬?

### DÃ¹ng ToG khi:
- âœ… CÃ³ sáºµn **structured knowledge graph** (Freebase, Wikidata)
- âœ… Cáº§n **multi-hop reasoning** rÃµ rÃ ng (3+ hops)
- âœ… Queries phá»©c táº¡p kiá»ƒu: "Where was the founder of X educated?"
- âœ… Cáº§n **explainability** cao (trace tá»«ng bÆ°á»›c)
- âœ… CÃ³ budget LLM calls (má»—i query = 3-5 calls)

### DÃ¹ng GraphRAG khi:
- âœ… Input lÃ  **unstructured documents** (MD, PDF, text)
- âœ… Cáº§n **extract knowledge** tá»« raw text
- âœ… Queries broad: "What are main themes?", "Summarize dataset"
- âœ… Cáº§n **speed** (1 LLM call cho answer)
- âœ… Dataset lá»›n, cáº§n scalability

---

## Chiáº¿n lÆ°á»£c Integration: ToG + GraphRAG

### Option 1: Hybrid Approach (Recommended) â­â­â­

**Káº¿t há»£p cáº£ hai** - dÃ¹ng GraphRAG Ä‘á»ƒ build graph, ToG Ä‘á»ƒ reasoning:

```
Documents
    â†“
GraphRAG Processing (Entity Extraction, Graph Construction)
    â†“
Knowledge Graph (Neo4j)
    â†“
Query Classification
    â†“
    â”œâ”€ Simple Queries â†’ GraphRAG Retrieval (fast)
    â”‚   â””â”€ Direct context assembly â†’ LLM answer
    â”‚
    â””â”€ Complex Queries â†’ ToG Reasoning (accurate)
        â””â”€ Multi-stage graph traversal â†’ Chained answer
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… Best of both worlds
- âœ… GraphRAG xá»­ lÃ½ documents â†’ build graph
- âœ… ToG reasoning trÃªn graph Ä‘Ã£ build
- âœ… Query routing: simple â†’ fast, complex â†’ accurate

**NhÆ°á»£c Ä‘iá»ƒm**:
- âš ï¸ Complex implementation
- âš ï¸ Cáº§n maintain 2 systems

---

### Option 2: ToG-Only Approach â­â­

**Chá»‰ dÃ¹ng ToG** - skip GraphRAG improvements:

```
Documents â†’ Manual Graph Construction â†’ ToG Reasoning â†’ Answer
```

**Khi nÃ o phÃ¹ há»£p**:
- âœ… Báº¡n Ä‘Ã£ cÃ³ **structured graph** sáºµn (khÃ´ng cáº§n extract tá»« documents)
- âœ… Queries chá»§ yáº¿u **phá»©c táº¡p, cáº§n reasoning**
- âœ… Dataset **nhá»** (khÃ´ng cáº§n scalability)
- âœ… Æ¯u tiÃªn **explainability** hÆ¡n speed

**GraphRAG improvements cÃ³ thá»ƒ skip**:
- âŒ Relationship prioritization (ToG tá»± rank relations)
- âŒ Token budget management (ToG query graph, Ã­t text)
- âŒ Community weighting (ToG khÃ´ng dÃ¹ng communities)
- âŒ Entity ranking (ToG score entities riÃªng)

**GraphRAG improvements NÃŠN GIá»®**:
- âœ… Entity extraction (náº¿u build graph tá»« documents)
- âœ… Graph construction (cáº§n graph Ä‘Ãºng format)
- âš ï¸ Text unit retrieval (optional - ToG cÃ³ thá»ƒ query graph trá»±c tiáº¿p)

---

### Option 3: GraphRAG-Only Approach â­â­â­

**Chá»‰ dÃ¹ng GraphRAG** - implement Ä‘áº§y Ä‘á»§ improvements:

```
Documents â†’ GraphRAG Processing â†’ Context Retrieval â†’ LLM Answer
```

**Khi nÃ o phÃ¹ há»£p**:
- âœ… Input lÃ  **unstructured documents**
- âœ… Queries chá»§ yáº¿u **simple-to-medium complexity**
- âœ… Cáº§n **speed** (< 5s response time)
- âœ… Dataset **lá»›n** (1000+ documents)
- âœ… Budget LLM calls **háº¡n cháº¿**

**Implement Ä‘áº§y Ä‘á»§ Phase 1**:
- âœ… Relationship prioritization
- âœ… Token budget management
- âœ… Community weighting
- âœ… Entity ranking

---

## Äá» xuáº¥t cho GraphToG project

### PhÃ¢n tÃ­ch hiá»‡n tráº¡ng:

Dá»± Ã¡n cá»§a báº¡n:
- âœ… Input: **Markdown documents** (unstructured)
- âœ… CÃ³ graph service (Neo4j)
- âœ… CÃ³ entity extraction
- âœ… CÃ³ community detection
- âœ… Queries: **mixed complexity**

### Chiáº¿n lÆ°á»£c Ä‘á» xuáº¥t: **Hybrid Approach (ToG + GraphRAG)** ğŸ¯

#### Phase 1: Implement Core GraphRAG (2 weeks)

**Má»¥c tiÃªu**: Build high-quality graph foundation

Implement:
1. âœ… **Entity Ranking** (1 day) - cáº§n cho cáº£ ToG vÃ  GraphRAG
2. âœ… **Token Budget Management** (2 days) - important cho GraphRAG retrieval
3. âš ï¸ **Relationship Prioritization** (2 days) - cÃ³ thá»ƒ skip náº¿u dÃ¹ng ToG reasoning
4. âš ï¸ **Community Weighting** (1 day) - skip náº¿u khÃ´ng dÃ¹ng global search

**LÃ½ do**:
- Entity ranking giÃºp ToG chá»n starting entities tá»‘t hÆ¡n
- Token budgets giÃºp fallback queries (khi ToG khÃ´ng phÃ¹ há»£p)
- Relationship prioritization cÃ³ thá»ƒ thay báº±ng ToG relation scoring

#### Phase 2: Implement ToG Reasoning (2 weeks)

**Má»¥c tiÃªu**: Add structured reasoning capability

Implement:
1. âœ… **ToG Prompts** (1 day)
   - Relation extraction prompt
   - Entity scoring prompt
   - Sufficiency evaluation prompt
   - Answer generation prompt

2. âœ… **Graph Query Functions** (2 days)
   - Get relations for entity
   - Get entities by relation
   - Multi-hop traversal
   - Triplet assembly

3. âœ… **ToG Service** (2 days)
   - Stage 1: Extract relevant relations
   - Stage 2: Score candidate entities
   - Stage 3: Multi-hop traversal
   - Stage 4: Evaluate sufficiency
   - Stage 5: Generate answer

4. âœ… **Query Router** (1 day)
   - Classify query complexity
   - Route simple â†’ GraphRAG
   - Route complex â†’ ToG

#### Phase 3: Optimization & Testing (1 week)

**Má»¥c tiÃªu**: Optimize performance, test thoroughly

1. âœ… Caching ToG intermediate results
2. âœ… Parallel relation scoring
3. âœ… Fallback strategies (ToG fails â†’ GraphRAG)
4. âœ… Performance benchmarks
5. âœ… Integration tests

---

## Implementation Roadmap cho Hybrid Approach

### Week 1-2: GraphRAG Core (Selective)

**Skip nhá»¯ng gÃ¬ khÃ´ng cáº§n**:
- âŒ Community weighting (ToG khÃ´ng dÃ¹ng)
- âŒ Full relationship prioritization (ToG tá»± rank)

**Implement nhá»¯ng gÃ¬ cáº§n**:
- âœ… Entity ranking (support ToG entity selection)
- âœ… Token budgets (fallback queries)
- âœ… Basic graph schema improvements

**Files to modify**:
- `backend/app/services/graph_service.py` - entity ranking
- `backend/app/services/retrieval_service.py` - basic token budgets
- `backend/requirements.txt` - add tiktoken

### Week 3-4: ToG Implementation

**New files to create**:

#### 1. `backend/app/services/tog_prompts.py`

```python
"""
ToG (Tree-of-Thoughts with Graph) prompt templates
Based on: https://github.com/GasolSun36/ToG
"""

EXTRACT_RELATIONS_PROMPT = """
Given a topic entity and a question, identify the most relevant relations to explore.

Topic Entity: {entity}
Question: {question}

Available Relations from this entity:
{available_relations}

Task: Score each relation's relevance (0.0 to 1.0, sum = 1.0).
Output format:
relation_name (Score: X.X)

Only include highly relevant relations. Irrelevant relations get 0.0.

Output:"""

SCORE_ENTITIES_PROMPT = """
Given candidate entities reached via a relation, score their relevance to answering the question.

Question: {question}
Relation used: {relation}
Current reasoning path: {path}

Candidate Entities:
{candidate_entities}

Task: Score each entity's relevance (0.0 to 1.0, sum = 1.0).
Output format:
entity_name (Score: X.X)

Output:"""

EVALUATE_SUFFICIENCY_PROMPT = """
Given retrieved triplets, evaluate if we have sufficient information to answer the question.

Question: {question}

Retrieved Triplets:
{triplets}

Task: Can we answer the question with these triplets?
Output format:
Sufficient: YES/NO
Reasoning: <brief explanation>
Missing: <what info is still needed, if any>

Output:"""

GENERATE_ANSWER_FROM_TRIPLETS_PROMPT = """
Answer the question using the retrieved knowledge graph triplets.

Question: {question}

Retrieved Triplets:
{triplets}

Task: Generate a coherent answer by chaining the triplets.
Use step-by-step reasoning.

Example format:
"First, [entity A] [relation] [entity B]. Second, [entity B] [relation] [entity C]. Therefore, the answer is [C]."

Answer:"""
```

#### 2. `backend/app/services/tog_service.py`

```python
"""
ToG (Tree-of-Thoughts with Graph) Service
Implements structured multi-hop reasoning on knowledge graph
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from app.services.graph_service import graph_service
from app.services.llm_service import llm_service
from app.services.tog_prompts import *

logger = logging.getLogger(__name__)

class ToGService:
    """
    Tree-of-Thoughts with Graph reasoning service

    Implements structured graph traversal and reasoning:
    1. Extract relevant relations
    2. Score candidate entities
    3. Multi-hop traversal (depth-first or breadth-first)
    4. Evaluate sufficiency
    5. Generate answer from triplets
    """

    def __init__(
        self,
        max_depth: int = 3,
        beam_width: int = 3,
        min_score_threshold: float = 0.1
    ):
        self.max_depth = max_depth
        self.beam_width = beam_width
        self.min_score_threshold = min_score_threshold

    def extract_relevant_relations(
        self,
        entity_id: str,
        question: str,
        available_relations: List[Dict[str, Any]]
    ) -> List[Tuple[str, float]]:
        """
        Stage 1: Extract and score relevant relations from entity

        Args:
            entity_id: Starting entity
            question: User question
            available_relations: List of relations from this entity

        Returns:
            List of (relation_type, score) tuples, sorted by score
        """
        # Format relations for prompt
        relations_text = "\n".join([
            f"- {rel['type']}: {rel.get('description', '')}"
            for rel in available_relations
        ])

        prompt = EXTRACT_RELATIONS_PROMPT.format(
            entity=entity_id,
            question=question,
            available_relations=relations_text
        )

        # Get LLM scoring
        response = llm_service.generate(prompt)

        # Parse scores
        scored_relations = self._parse_relation_scores(response)

        # Filter by threshold and sort
        filtered = [
            (rel, score) for rel, score in scored_relations
            if score >= self.min_score_threshold
        ]

        return sorted(filtered, key=lambda x: x[1], reverse=True)

    def score_candidate_entities(
        self,
        question: str,
        relation: str,
        candidates: List[Dict[str, Any]],
        current_path: List[Dict]
    ) -> List[Tuple[str, float]]:
        """
        Stage 2: Score candidate entities reached via relation

        Args:
            question: User question
            relation: Relation type used
            candidates: Candidate entities
            current_path: Current reasoning path (triplets so far)

        Returns:
            List of (entity_id, score) tuples
        """
        # Format candidates
        candidates_text = "\n".join([
            f"- {c['name']}: {c.get('description', '')}"
            for c in candidates
        ])

        # Format path
        path_text = " -> ".join([
            f"{t['source']} --{t['relation']}--> {t['target']}"
            for t in current_path
        ])

        prompt = SCORE_ENTITIES_PROMPT.format(
            question=question,
            relation=relation,
            candidate_entities=candidates_text,
            path=path_text if path_text else "Starting exploration"
        )

        response = llm_service.generate(prompt)

        # Parse scores
        scored_entities = self._parse_entity_scores(response)

        # Filter and sort
        filtered = [
            (ent, score) for ent, score in scored_entities
            if score >= self.min_score_threshold
        ]

        return sorted(filtered, key=lambda x: x[1], reverse=True)[:self.beam_width]

    def traverse_graph(
        self,
        start_entity_id: str,
        question: str,
        max_hops: int = None
    ) -> List[Dict[str, Any]]:
        """
        Stage 3: Multi-hop graph traversal with beam search

        Args:
            start_entity_id: Starting entity
            question: User question
            max_hops: Maximum traversal depth (default: self.max_depth)

        Returns:
            List of triplets (paths through graph)
        """
        max_hops = max_hops or self.max_depth

        # Track collected triplets
        all_triplets = []

        # Beam search: maintain top-K paths
        current_beams = [{
            "entity_id": start_entity_id,
            "path": [],
            "score": 1.0,
            "depth": 0
        }]

        for depth in range(max_hops):
            next_beams = []

            for beam in current_beams:
                entity_id = beam["entity_id"]
                current_path = beam["path"]

                # Get available relations from current entity
                relations = graph_service.get_entity_relations(entity_id)

                if not relations:
                    continue

                # Stage 1: Score relations
                scored_relations = self.extract_relevant_relations(
                    entity_id=entity_id,
                    question=question,
                    available_relations=relations
                )

                # Explore top relations
                for relation_type, rel_score in scored_relations[:self.beam_width]:
                    # Get entities via this relation
                    candidates = graph_service.get_entities_by_relation(
                        entity_id=entity_id,
                        relation_type=relation_type
                    )

                    if not candidates:
                        continue

                    # Stage 2: Score candidate entities
                    scored_entities = self.score_candidate_entities(
                        question=question,
                        relation=relation_type,
                        candidates=candidates,
                        current_path=current_path
                    )

                    # Add to next beams
                    for target_id, ent_score in scored_entities:
                        triplet = {
                            "source": entity_id,
                            "relation": relation_type,
                            "target": target_id,
                            "score": rel_score * ent_score
                        }

                        new_path = current_path + [triplet]
                        all_triplets.append(triplet)

                        next_beams.append({
                            "entity_id": target_id,
                            "path": new_path,
                            "score": beam["score"] * triplet["score"],
                            "depth": depth + 1
                        })

            # Prune: keep top beams
            current_beams = sorted(
                next_beams,
                key=lambda x: x["score"],
                reverse=True
            )[:self.beam_width]

            if not current_beams:
                break

        return all_triplets

    def evaluate_sufficiency(
        self,
        question: str,
        triplets: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Stage 4: Evaluate if retrieved triplets are sufficient to answer

        Args:
            question: User question
            triplets: Retrieved graph triplets

        Returns:
            Dict with sufficiency evaluation
        """
        # Format triplets
        triplets_text = "\n".join([
            f"- {t['source']} --{t['relation']}--> {t['target']}"
            for t in triplets
        ])

        prompt = EVALUATE_SUFFICIENCY_PROMPT.format(
            question=question,
            triplets=triplets_text
        )

        response = llm_service.generate(prompt)

        # Parse response
        is_sufficient = "YES" in response.upper()

        return {
            "sufficient": is_sufficient,
            "evaluation": response,
            "triplet_count": len(triplets)
        }

    def generate_answer(
        self,
        question: str,
        triplets: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Stage 5: Generate answer from triplets

        Args:
            question: User question
            triplets: Retrieved triplets

        Returns:
            Dict with answer and metadata
        """
        # Format triplets
        triplets_text = "\n".join([
            f"{i+1}. {t['source']} --{t['relation']}--> {t['target']}"
            for i, t in enumerate(triplets)
        ])

        prompt = GENERATE_ANSWER_FROM_TRIPLETS_PROMPT.format(
            question=question,
            triplets=triplets_text
        )

        answer = llm_service.generate(prompt)

        return {
            "answer": answer,
            "triplets_used": triplets,
            "reasoning_steps": len(triplets),
            "method": "tog"
        }

    def process_query(
        self,
        question: str,
        start_entity: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Complete ToG reasoning pipeline

        Args:
            question: User question
            start_entity: Starting entity (auto-detected if None)

        Returns:
            Dict with answer and reasoning trace
        """
        logger.info(f"ToG processing query: {question}")

        # Step 0: Find starting entity if not provided
        if not start_entity:
            # Extract entities from question using LLM
            entities = llm_service.extract_entities(question)
            if entities and entities.get("entities"):
                start_entity = entities["entities"][0]["name"]
            else:
                return {
                    "status": "error",
                    "message": "Could not identify starting entity"
                }

        # Find entity in graph
        entity_node = graph_service.find_entity_by_name(start_entity)
        if not entity_node:
            return {
                "status": "error",
                "message": f"Entity '{start_entity}' not found in graph"
            }

        start_entity_id = entity_node["id"]

        # Step 1-3: Traverse graph and collect triplets
        logger.info(f"Starting graph traversal from: {start_entity}")
        triplets = self.traverse_graph(
            start_entity_id=start_entity_id,
            question=question
        )

        logger.info(f"Collected {len(triplets)} triplets")

        if not triplets:
            return {
                "status": "no_paths",
                "message": "No relevant paths found in graph"
            }

        # Step 4: Evaluate sufficiency
        sufficiency = self.evaluate_sufficiency(question, triplets)

        # Step 5: Generate answer
        result = self.generate_answer(question, triplets)

        result["status"] = "success"
        result["start_entity"] = start_entity
        result["sufficiency"] = sufficiency
        result["llm_calls"] = 1 + len(triplets) * 2 + 2  # Extract + (rel + ent) * N + eval + answer

        return result

    def _parse_relation_scores(self, response: str) -> List[Tuple[str, float]]:
        """Parse relation scores from LLM response"""
        scores = []
        for line in response.strip().split("\n"):
            if "Score:" in line:
                parts = line.split("(Score:")
                if len(parts) == 2:
                    rel_name = parts[0].strip().strip("-").strip()
                    score_str = parts[1].strip().rstrip(")").strip()
                    try:
                        score = float(score_str)
                        scores.append((rel_name, score))
                    except ValueError:
                        continue
        return scores

    def _parse_entity_scores(self, response: str) -> List[Tuple[str, float]]:
        """Parse entity scores from LLM response"""
        # Same format as relations
        return self._parse_relation_scores(response)

# Singleton
tog_service = ToGService()
```

#### 3. `backend/app/services/query_router.py`

```python
"""
Query Router: Decide between GraphRAG and ToG
"""

import logging
from typing import Dict, Any
from app.services.llm_service import llm_service

logger = logging.getLogger(__name__)

class QueryRouter:
    """Routes queries to appropriate processing method"""

    def classify_query_complexity(self, query: str) -> Dict[str, Any]:
        """
        Classify query to determine routing

        Returns:
            {
                "complexity": "simple" | "complex",
                "reasoning": "explanation",
                "method": "graphrag" | "tog"
            }
        """
        prompt = f"""
Classify the query complexity:

Query: "{query}"

Classification criteria:
- SIMPLE: Direct facts, single-hop, straightforward lookup
  Examples: "What is X?", "Who founded Y?"
  â†’ Use GraphRAG (fast retrieval)

- COMPLEX: Multi-hop reasoning, requires chaining facts
  Examples: "Where was X's founder educated?", "What connects A and B?"
  â†’ Use ToG (structured reasoning)

Output JSON:
{{
    "complexity": "simple" or "complex",
    "reasoning": "brief explanation",
    "hops_needed": 1-5
}}
"""

        response = llm_service.generate(prompt)
        classification = llm_service._parse_json_response(response)

        # Route based on complexity
        complexity = classification.get("complexity", "simple")
        method = "tog" if complexity == "complex" else "graphrag"

        classification["method"] = method

        logger.info(f"Query routed to {method}: {classification.get('reasoning')}")

        return classification

query_router = QueryRouter()
```

#### 4. Update `backend/app/api/endpoints/queries.py`

```python
@router.post("/query/auto")
def query_auto_route(
    query_request: QueryRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Auto-route query to GraphRAG or ToG based on complexity

    - Simple queries â†’ GraphRAG (fast)
    - Complex queries â†’ ToG (accurate multi-hop)
    """
    from app.services.query_router import query_router
    from app.services.tog_service import tog_service
    from app.services.query_service import query_service

    # Classify query
    routing = query_router.classify_query_complexity(query_request.query)

    if routing["method"] == "tog":
        # Use ToG for complex reasoning
        result = tog_service.process_query(
            question=query_request.query,
            start_entity=query_request.get("entity")  # Optional
        )
    else:
        # Use GraphRAG for simple queries
        result = query_service.process_query(
            query=query_request.query,
            hop_limit=query_request.get("hop_limit", 1)
        )

    result["routing"] = routing

    # Save query to database
    # ... (existing code)

    return result
```

### Week 5: Testing & Optimization

1. âœ… Test ToG vá»›i complex queries
2. âœ… Test GraphRAG vá»›i simple queries
3. âœ… Test routing logic
4. âœ… Performance optimization (caching, parallel calls)
5. âœ… Fallback strategies

---

## Final Recommendation

### **Chiáº¿n lÆ°á»£c Ä‘á» xuáº¥t cho GraphToG**: Hybrid Approach

**Implement**:
1. **Week 1-2**: Minimal GraphRAG
   - âœ… Entity ranking (support cáº£ ToG láº«n GraphRAG)
   - âœ… Basic token budgets (cho fallback)
   - âŒ Skip relationship prioritization (ToG tá»± lÃ m)
   - âŒ Skip community weighting (khÃ´ng cáº§n cho ToG)

2. **Week 3-4**: ToG Implementation
   - âœ… ToG prompts
   - âœ… ToG service (5 stages)
   - âœ… Query router
   - âœ… Graph query helpers

3. **Week 5**: Integration & Testing
   - âœ… Auto-routing endpoint
   - âœ… Fallback logic
   - âœ… Performance optimization

**Káº¿t quáº£**:
- âœ… Simple queries: Fast GraphRAG retrieval (< 5s)
- âœ… Complex queries: Accurate ToG reasoning (10-30s)
- âœ… Best of both worlds
- âœ… Chá»‰ implement ~40% GraphRAG improvements (tiáº¿t kiá»‡m thá»i gian)
- âœ… Focus effort vÃ o ToG (unique value)

**Cost**:
- 5 tuáº§n instead of 8 tuáº§n (full GraphRAG)
- Tiáº¿t kiá»‡m 3 tuáº§n (~37%)
- Better explainability vÃ  reasoning

---

## Káº¿t luáº­n

**Tráº£ lá»i cÃ¢u há»i ban Ä‘áº§u:**

> Náº¿u cÃ i Ä‘áº·t ToG cho retrieval vÃ  sinh cÃ¢u tráº£ lá»i, cÃ³ cáº§n thá»±c hiá»‡n Ä‘áº§y Ä‘á»§ GraphRAG improvements khÃ´ng?

**KHÃ”NG Cáº¦N** implement Ä‘áº§y Ä‘á»§ táº¥t cáº£ GraphRAG improvements.

**Chá»‰ cáº§n implement**:
- âœ… Entity ranking (há»— trá»£ ToG)
- âœ… Basic token budgets (fallback)
- âœ… Graph schema improvements (quality)

**CÃ³ thá»ƒ skip**:
- âŒ Relationship prioritization (ToG tá»± rank)
- âŒ Community weighting (ToG khÃ´ng dÃ¹ng communities)
- âŒ Advanced context assembly (ToG query graph trá»±c tiáº¿p)

**Focus vÃ o**:
- â­ ToG implementation (reasoning layer)
- â­ Query routing (phÃ¢n loáº¡i complexity)
- â­ Hybrid approach (best of both)

CÃ¡ch nÃ y **tiáº¿t kiá»‡m thá»i gian** (5 tuáº§n vs 8 tuáº§n) vÃ  mang láº¡i **unique value** (structured reasoning) mÃ  pure GraphRAG khÃ´ng cÃ³!
