# GraphRAG Implementation - Tasks & Improvements

Danh s√°ch c√°c tasks ƒë·ªÉ √°p d·ª•ng ho√†n ch·ªânh GraphRAG methodology theo chu·∫©n Microsoft.

**Tr·∫°ng th√°i hi·ªán t·∫°i: 9.0/10** - Core implementation ho√†n ch·ªânh, c·∫ßn th√™m advanced features v√† optimization.

---

## üî¥ Priority 1: Critical (High Impact)

### 1.1 Prompt Tuning cho Domain-Specific Data
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Microsoft khuy·∫øn ngh·ªã m·∫°nh m·∫Ω)

- [ ] Ch·∫°y prompt tuning tr√™n sample documents ƒë·ªÉ generate domain-specific prompts
- [ ] T·∫°o custom entity types ph√π h·ª£p v·ªõi domain c·ªßa project
  - V√≠ d·ª•: TECHNOLOGY, CONCEPT, ALGORITHM, DATASET, MODEL, LIBRARY, API
- [ ] Custom relationship types cho domain
  - V√≠ d·ª•: IMPLEMENTS, USES, DEPENDS_ON, EXTENDS
- [ ] T·∫°o prompt variants trong `backend/app/services/prompt.py`
- [ ] A/B test gi·ªØa default prompts v√† custom prompts
- [ ] ƒêo l∆∞·ªùng improvement: entity precision, relationship accuracy
- [ ] Document best practices trong `docs/prompt-tuning.md`

**Files c·∫ßn modify:**
- `backend/app/services/prompt.py` - Th√™m custom prompt variants
- `backend/app/config.py` - Add config cho prompt selection
- `backend/app/services/llm_service.py` - Support multiple prompt templates

**References:**
- https://microsoft.github.io/graphrag/posts/prompt_tuning/
- https://microsoft.github.io/graphrag/posts/config/init/

---

### 1.2 Monitoring & Observability
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

- [ ] Add logging cho t·∫•t c·∫£ LLM calls (latency, tokens, cost)
- [ ] Track extraction quality metrics:
  - Entity extraction success rate
  - Relationship extraction success rate
  - Community detection quality (modularity score)
- [ ] Query performance monitoring:
  - Query latency by type (local/global/hybrid)
  - Cache hit rate
  - Context retrieval quality
- [ ] Dashboard v·ªõi Grafana/Prometheus ho·∫∑c t√≠ch h·ª£p v√†o admin panel
- [ ] Alert khi extraction quality gi·∫£m

**Files c·∫ßn t·∫°o:**
- `backend/app/services/monitoring.py` - Metrics collection
- `backend/app/services/metrics.py` - Quality metrics calculation
- `backend/app/middleware/logging.py` - Request/response logging

---

### 1.3 Error Handling & Resilience
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê

- [ ] Graceful degradation khi LLM API fails
  - Fallback to cached results
  - Partial results instead of complete failure
- [ ] Better error messages cho users
- [ ] Retry logic v·ªõi exponential backoff cho transient failures (ƒë√£ c√≥, c·∫ßn improve)
- [ ] Circuit breaker pattern cho LLM service
- [ ] Dead letter queue cho failed extraction jobs
- [ ] Recovery mechanism cho incomplete document processing

**Files c·∫ßn modify:**
- `backend/app/services/llm_service.py` - Circuit breaker, better retry
- `backend/app/services/document_processor.py` - Recovery logic
- `backend/app/api/endpoints/*.py` - Better error responses

---

## üü† Priority 2: Important (Medium Impact)

### 2.1 Map-Reduce Global Search
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê

- [x] Implement Map-Reduce pattern cho global query processing
  - Map phase: Chia communities th√†nh batches, summarize t·ª´ng batch
  - Reduce phase: Combine intermediate summaries th√†nh final answer
- [x] Configurable batch size (default: 10 communities/batch)
- [x] Parallel processing cho Map phase
- [x] Compare performance vs current concatenation approach
- [x] Add config option ƒë·ªÉ switch gi·ªØa Map-Reduce v√† simple concatenation

**Implementation outline:**
```python
# backend/app/services/query_service.py
async def process_global_query_with_mapreduce(
    query: str,
    batch_size: int = 10
):
    # 1. Retrieve all communities
    communities = await retrieval_service.retrieve_global_context()

    # 2. Map: Batch processing
    batches = chunk_list(communities, batch_size)
    intermediate_summaries = []

    for batch in batches:
        batch_summary = await llm_service.summarize_community_batch(
            query, batch
        )
        intermediate_summaries.append(batch_summary)

    # 3. Reduce: Final synthesis
    final_answer = await llm_service.synthesize_final_answer(
        query, intermediate_summaries
    )

    return final_answer
```

**Files c·∫ßn modify:**
- `backend/app/services/query_service.py` - Add Map-Reduce method
- `backend/app/services/llm_service.py` - Add batch summarization
- `backend/app/services/prompt.py` - Add Map-Reduce prompts
- `backend/app/config.py` - Add config options

**References:**
- https://microsoft.github.io/graphrag/posts/query/global_search/

---

### 2.2 Claims Extraction & Storage
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê

- [x] Integrate claims extraction v√†o document processing pipeline
- [x] Extend Neo4j schema v·ªõi Claim nodes
  - Properties: subject, object, claim_type, status, description, date_range
- [x] Store claims v·ªõi relationships:
  - `Entity -[:MAKES_CLAIM]-> Claim`
  - `Claim -[:ABOUT]-> Entity`
  - `Claim -[:SOURCED_FROM]-> TextUnit`
- [x] Query service support cho claim-based queries
- [x] UI ƒë·ªÉ display claims trong document analysis
- [x] Claim verification workflow (optional)

**Neo4j Schema Extension:**
```cypher
CREATE CONSTRAINT claim_id IF NOT EXISTS
FOR (c:Claim) REQUIRE c.id IS UNIQUE;

CREATE INDEX claim_type IF NOT EXISTS
FOR (c:Claim) ON (c.claim_type);

CREATE INDEX claim_status IF NOT EXISTS
FOR (c:Claim) ON (c.status);
```

**Files c·∫ßn modify:**
- `backend/app/services/document_processor.py` - Add claims extraction step
- `backend/app/services/llm_service.py` - Add `extract_claims()` method
- `backend/app/services/graph_service.py` - Add claims storage methods
- `backend/app/models/claim.py` - NEW: Claim model
- `backend/app/schemas/claim.py` - NEW: Claim schemas

**References:**
- Prompt template ƒë√£ c√≥: `backend/app/services/prompt.py:158-209`

---

### 2.3 DRIFT Search Implementation
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê

- [ ] Implement DRIFT (Dynamic Reasoning with Inference over Text) search
- [ ] DRIFT = Local search + Community context enrichment
- [ ] Add to query routing logic
- [ ] Performance comparison v·ªõi pure local search

**Implementation outline:**
```python
# backend/app/services/retrieval_service.py
async def retrieve_drift_context(
    query_entity: str,
    hop_limit: int = 2,
    include_community_summaries: bool = True
) -> Dict:
    # 1. Local context retrieval
    local_results = await retrieve_local_context(
        query_entity, hop_limit, include_text=True
    )

    # 2. Community context enrichment
    if include_community_summaries:
        community_context = await retrieve_community_context(
            query_entity, include_summaries=True
        )

        # Merge contexts
        enriched_context = merge_local_and_community(
            local_results, community_context
        )
        return enriched_context

    return local_results
```

**Files c·∫ßn modify:**
- `backend/app/services/retrieval_service.py` - Add DRIFT methods
- `backend/app/services/query_service.py` - Add DRIFT query processing
- `backend/app/api/endpoints/queries.py` - Add DRIFT endpoint

**References:**
- https://microsoft.github.io/graphrag/posts/query/drift_search/

---

### 2.4 Entity Resolution & Disambiguation
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê

- [ ] Improve entity deduplication beyond MD5 hash
- [ ] Fuzzy matching cho entity names (Levenshtein distance)
- [ ] LLM-based entity resolution cho ambiguous cases
- [ ] Merge duplicate entities sau khi detection
- [ ] Entity alias tracking (e.g., "Microsoft" = "MS" = "MSFT")

**Implementation:**
```python
# backend/app/services/entity_resolution.py - NEW FILE
class EntityResolutionService:
    def find_similar_entities(
        self,
        entity_name: str,
        entity_type: str,
        threshold: float = 0.85
    ):
        # Fuzzy matching logic
        pass

    def merge_duplicate_entities(
        self,
        entity_ids: List[str]
    ):
        # Merge logic with mention_count aggregation
        pass

    async def resolve_with_llm(
        self,
        entity1: Dict,
        entity2: Dict
    ) -> bool:
        # LLM-based resolution for edge cases
        pass
```

**Files c·∫ßn t·∫°o:**
- `backend/app/services/entity_resolution.py` - NEW
- `backend/app/api/endpoints/admin.py` - Add entity merge endpoints

---

### 2.5 Incremental Indexing ‚úÖ COMPLETED
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê

- [x] Support incremental document updates (kh√¥ng ph·∫£i reindex to√†n b·ªô)
- [x] Track document versions trong PostgreSQL
- [x] Update existing entities thay v√¨ recreate
- [x] Incremental community detection (ch·ªâ recompute affected communities)
- [x] Efficient graph updates

**Implementation Details:**
- Added version tracking fields to Document model (version, content_hash, last_processed_at)
- Implemented SHA256-based change detection to skip unchanged documents
- Created `process_document_incrementally()` for efficient updates
- Added `get_affected_communities_for_document()` and `delete_document_graph_data()` to graph service
- Implemented `detect_communities_incrementally()` for subgraph-only community detection
- Added API endpoints: PUT /documents/{id}/update, POST /documents/{id}/reprocess
- Comprehensive test suite with 20+ tests including integration and performance benchmarks

**Files modified:**
- ‚úÖ `backend/app/models/document.py` - Added version, content_hash, last_processed_at fields
- ‚úÖ `backend/app/schemas/document.py` - Updated DocumentResponse schema
- ‚úÖ `backend/app/services/document_processor.py` - Incremental processing logic
- ‚úÖ `backend/app/services/graph_service.py` - Update operations and cleanup methods
- ‚úÖ `backend/app/services/community_detection.py` - Incremental detection
- ‚úÖ `backend/app/api/endpoints/documents.py` - Update and reprocess endpoints
- ‚úÖ `backend/tests/test_incremental_indexing.py` - Comprehensive test suite

**Documentation:** See `INCREMENTAL_INDEXING.md` for usage guide

**Completed:** 2025-10-30

---

### 3.3 Query Optimization & Caching
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê

- [ ] Semantic query caching (similar queries ‚Üí cached results)
- [ ] Embedding-based query similarity
- [ ] Cache warming cho popular queries
- [ ] Query result ranking improvement
- [ ] Relevance feedback loop

**Files c·∫ßn modify:**
- `backend/app/services/cache_service.py` - Semantic caching
- `backend/app/services/embedding_service.py` - Query embeddings
- `backend/app/services/query_service.py` - Cache integration

---

### 3.4 Batch Document Processing
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê

- [ ] Bulk upload interface (multiple files)
- [ ] Background job queue (Celery/RQ)
- [ ] Progress tracking cho long-running jobs
- [ ] Parallel document processing
- [ ] Batch status dashboard

**Files c·∫ßn t·∫°o:**
- `backend/app/workers/` - Background workers
- `backend/app/services/job_queue.py` - Queue management
- `frontend/components/batch-upload/` - Bulk upload UI

---

### 3.5 Graph Analytics & Insights
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê

- [ ] Centrality metrics (PageRank, Betweenness, Closeness)
- [ ] Entity importance scoring
- [ ] Knowledge gap detection (sparse areas in graph)
- [ ] Relationship pattern mining
- [ ] Temporal analysis (entity evolution over time)

**Implementation:**
```python
# backend/app/services/graph_analytics.py - NEW FILE
class GraphAnalyticsService:
    def calculate_centrality(self):
        # Use Neo4j GDS algorithms
        pass

    def detect_knowledge_gaps(self):
        # Find under-connected entities
        pass

    def mine_relationship_patterns(self):
        # Frequent pattern mining
        pass
```

---

### 3.6 Export & Integration
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê

- [ ] Export knowledge graph (GraphML, GEXF, JSON)
- [ ] Export community reports (PDF, DOCX)
- [ ] REST API cho external integrations
- [ ] Webhook support cho events (document processed, etc.)
- [ ] Integration v·ªõi tools kh√°c (Obsidian, Notion, etc.)

**Files c·∫ßn t·∫°o:**
- `backend/app/services/export_service.py` - Export logic
- `backend/app/api/endpoints/export.py` - Export endpoints

---

### 3.7 Testing & Quality Assurance
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

- [ ] Expand test coverage to 80%+
- [ ] Integration tests cho full pipeline
- [ ] Performance benchmarks
- [ ] Load testing (concurrent users, large documents)
- [ ] Extraction quality regression tests
- [ ] End-to-end tests cho query flows

**Files c·∫ßn t·∫°o:**
- `backend/tests/integration/test_full_pipeline.py`
- `backend/tests/performance/test_benchmarks.py`
- `backend/tests/quality/test_extraction_quality.py`

---

### 3.8 Documentation Improvements
**T·∫ßm quan tr·ªçng:** ‚≠ê‚≠ê‚≠ê

- [ ] API documentation v·ªõi examples
- [ ] Architecture diagrams
- [ ] Deployment guide
- [ ] Troubleshooting guide
- [ ] Performance tuning guide
- [ ] Video tutorials

**Files c·∫ßn t·∫°o:**
- `docs/api/README.md`
- `docs/architecture/diagrams/`
- `docs/deployment/production.md`
- `docs/guides/troubleshooting.md`

---

## üìä Implementation Roadmap

### Phase 1: Stability & Observability (2-3 weeks)
- Priority 1.2: Monitoring & Observability
- Priority 1.3: Error Handling & Resilience
- Priority 3.7: Testing expansion

### Phase 2: Core Enhancements (3-4 weeks)
- Priority 1.1: Prompt Tuning
- Priority 2.1: Map-Reduce Global Search
- Priority 2.4: Entity Resolution
- Priority 2.5: Incremental Indexing

### Phase 3: Advanced Features (4-6 weeks)
- Priority 2.2: Claims Extraction
- Priority 2.3: DRIFT Search
- Priority 3.2: Advanced Visualization
- Priority 3.3: Query Optimization

### Phase 4: Optimization & Scale (2-3 weeks)
- Priority 3.4: Batch Processing
- Priority 3.5: Graph Analytics
- Priority 3.6: Export & Integration

---

## üéØ Success Metrics

### Extraction Quality
- Entity precision/recall > 85%
- Relationship accuracy > 80%
- Community modularity > 0.4

### Performance
- Document processing: < 2 min per 10K tokens
- Local query: < 3s response time
- Global query: < 10s response time
- Cache hit rate: > 60%

### User Experience
- Query satisfaction score: > 4/5
- System uptime: > 99.5%
- Error rate: < 1%

---

## üìö References

### Microsoft GraphRAG Documentation
- Main docs: https://microsoft.github.io/graphrag/
- Prompt tuning: https://microsoft.github.io/graphrag/posts/prompt_tuning/
- Query methods: https://microsoft.github.io/graphrag/posts/query/overview/
- Configuration: https://microsoft.github.io/graphrag/posts/config/overview/

### Neo4j Resources
- GDS Library: https://neo4j.com/docs/graph-data-science/current/
- Leiden Algorithm: https://neo4j.com/docs/graph-data-science/current/algorithms/leiden/
- Performance tuning: https://neo4j.com/docs/operations-manual/current/performance/

### Research Papers
- Graph Retrieval-Augmented Generation: https://arxiv.org/abs/2404.16130
- Leiden Algorithm: https://www.nature.com/articles/s41598-019-41695-z

---

## üí° Notes

- T·∫•t c·∫£ tasks n√™n c√≥ unit tests v√† documentation
- Performance impact ph·∫£i ƒë∆∞·ª£c ƒëo l∆∞·ªùng tr∆∞·ªõc v√† sau optimization
- Breaking changes c·∫ßn migration scripts
- User-facing features c·∫ßn user testing tr∆∞·ªõc khi deploy

**Last updated:** 2025-10-30
