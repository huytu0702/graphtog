# So S√°nh Quy Tr√¨nh Index Document: GraphToG vs Microsoft GraphRAG

**Ng√†y ph√¢n t√≠ch:** 2025-11-07
**M·ª•c ƒë√≠ch:** So s√°nh chi ti·∫øt quy tr√¨nh x·ª≠ l√Ω v√† index document gi·ªØa h·ªá th·ªëng GraphToG (codebase hi·ªán t·∫°i) v√† Microsoft GraphRAG

---

## T·ªïng Quan Ki·∫øn Tr√∫c

### Microsoft GraphRAG
- **M√¥ h√¨nh:** Pipeline tu·∫ßn t·ª± v·ªõi 7 phases ch√≠nh
- **LLM:** S·ª≠ d·ª•ng LLM l√†m trung t√¢m cho extraction v√† summarization
- **Graph Database:** Kh√¥ng b·∫Øt bu·ªôc (c√≥ th·ªÉ l∆∞u d·∫°ng file)
- **Focus:** Hierarchical community-based reasoning cho global queries

### GraphToG
- **M√¥ h√¨nh:** Pipeline t√≠ch h·ª£p v·ªõi Neo4j + PostgreSQL
- **LLM:** Google Gemini 2.5 Flash
- **Graph Database:** Neo4j (b·∫Øt bu·ªôc) + PostgreSQL + Redis
- **Focus:** Tree of Graphs (ToG) multi-hop reasoning cho complex queries

---

## So S√°nh Chi Ti·∫øt T·ª´ng B∆∞·ªõc

### 1. Document Parsing & Loading

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Input format** | CSV, .txt files | Markdown (.md) files only |
| **Implementation** | Built-in document loaders | Custom `DocumentProcessor.parse_md()` |
| **File validation** | Multiple formats supported | Only `.md` extension validated |
| **Content hash** | ‚ùå Kh√¥ng c√≥ | ‚úÖ SHA256 hash tracking (`compute_content_hash()`) |
| **Change detection** | ‚ùå Kh√¥ng c√≥ | ‚úÖ Incremental update support (`detect_document_changes()`) |
| **Metadata storage** | File-based ho·∫∑c database | PostgreSQL (Document table) + Neo4j (Document node) |

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:** C√≥ change detection v√† incremental update
- ‚úÖ **GraphRAG linh ho·∫°t h∆°n:** H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng file
- ‚ö†Ô∏è **GraphToG h·∫°n ch·∫ø:** Ch·ªâ h·ªó tr·ª£ Markdown

---

### 2. Text Chunking (Text Segmentation)

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Chunk size** | 300 tokens (default, configurable) | 1000 tokens (default, configurable) |
| **Overlap** | ‚ùå Kh√¥ng c√≥ overlap | ‚úÖ 500 tokens overlap (default) |
| **Tokenizer** | LLM-specific tokenizer | tiktoken (GPT-3.5-turbo encoding) |
| **Splitting strategy** | Token-based | Semantic-aware: paragraphs ‚Üí sentences ‚Üí tokens |
| **Min chunk size** | Kh√¥ng r√µ | 100 tokens (configurable) |
| **Implementation** | `compose_text_units` verb | `ChunkingService.create_chunks()` |
| **Metadata tracking** | TextUnit v·ªõi document links | TextUnit v·ªõi start_char, end_char, document_id |

**Code snippet GraphToG:**
```python
# chunking_service.py
def create_chunks(self, text: str) -> List[Tuple[str, int, int]]:
    """Create chunks with overlap and semantic awareness"""
    # 1. Split by paragraphs first
    paragraphs = self.split_by_paragraphs(text)

    # 2. Accumulate until chunk_size reached
    # 3. Create overlap for context continuity
    # 4. If paragraph too large, split by sentences
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Overlap gi√∫p maintain context gi·ªØa c√°c chunks
  - Semantic-aware splitting (paragraph-level)
  - Character position tracking cho retrieval
- ‚úÖ **GraphRAG ƒë∆°n gi·∫£n h∆°n:** Chunk nh·ªè h∆°n (300 tokens) c√≥ th·ªÉ gi·∫£m cost LLM extraction
- ‚ö†Ô∏è **Trade-off:** GraphToG chunks l·ªõn h∆°n ‚Üí nhi·ªÅu th√¥ng tin h∆°n nh∆∞ng LLM cost cao h∆°n

---

### 3. Entity Extraction

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Method** | LLM-based extraction | LLM-based (Gemini) + batch processing |
| **Entity attributes** | title, type, description | name, type, description, confidence |
| **Entity types** | User-configurable | PERSON, ORGANIZATION, LOCATION, CONCEPT, EVENT, PRODUCT, OTHER |
| **Batch processing** | ‚úÖ (entity_extract verb) | ‚úÖ `batch_extract_entities()` |
| **Coreference resolution** | ‚ùå Kh√¥ng c√≥ | ‚úÖ `resolve_coreferences()` (advanced_extraction) |
| **Few-shot learning** | ‚úÖ (prompt tuning) | ‚úÖ `extract_with_few_shot()` |
| **Deduplication** | Merged in summarization phase | ‚úÖ Immediate via `create_or_merge_entity()` |
| **Mention count tracking** | ‚ùå | ‚úÖ Auto-increment on merge |

**Code snippet GraphToG:**
```python
# document_processor.py - Step 7
entity_results = await llm_service.batch_extract_entities(chunk_data)

for result in entity_results:
    if result["status"] == "success":
        for entity in result["entities"]:
            entity_id = graph_service.create_or_merge_entity(
                name=entity.get("name", ""),
                entity_type=entity.get("type", "OTHER"),
                description=entity.get("description", ""),
                confidence=entity.get("confidence", 0.8),
            )
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Immediate deduplication via MERGE
  - Mention count tracking (h·ªØu √≠ch cho ToG ranking)
  - Confidence scoring
  - Coreference resolution support
- ‚úÖ **GraphRAG:** T√°ch bi·ªát extraction v√† summarization ‚Üí c√≥ th·ªÉ optimize ri√™ng
- üü∞ **T∆∞∆°ng ƒë∆∞∆°ng:** C·∫£ hai ƒë·ªÅu d√πng LLM extraction v·ªõi few-shot learning

---

### 4. Entity Resolution & Disambiguation

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Phase** | Phase 2b (Graph Extraction) | Step 7.5 (Optional, after extraction) |
| **Method** | LLM summarization of duplicate instances | Fuzzy matching + LLM resolution |
| **Fuzzy matching** | ‚ùå | ‚úÖ SequenceMatcher (difflib) |
| **Similarity threshold** | N/A | 0.85 (default, configurable) |
| **LLM verification** | ‚úÖ (summarization) | ‚úÖ `resolve_with_llm()` (optional) |
| **Auto-merge threshold** | N/A | 0.95+ (high confidence) |
| **Merge strategy** | Consolidate descriptions | Transfer relationships + mention counts + aliases |
| **Alias tracking** | ‚ùå | ‚úÖ Entity aliases stored |
| **Incremental** | ‚ùå | ‚úÖ Can skip if disabled |

**Code snippet GraphToG:**
```python
# entity_resolution_service.py
def find_duplicate_entity_pairs(self, entity_type=None, threshold=0.85):
    """Find duplicate pairs using fuzzy matching"""
    similarity = self.calculate_similarity(entity1["name"], entity2["name"])
    if similarity >= threshold:
        duplicate_pairs.append((entity1, entity2, similarity))

async def resolve_with_llm(self, entity1, entity2):
    """Use LLM to verify if entities are the same"""
    # Prompt: "Are these names referring to the same entity?"
    # Returns: {are_same, confidence, reasoning, suggested_canonical_name}
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG v∆∞·ª£t tr·ªôi:**
  - 3-stage resolution: fuzzy ‚Üí LLM verification ‚Üí merge
  - Configurable thresholds (similarity, auto-merge, LLM)
  - Alias tracking cho better retrieval
  - Optional (c√≥ th·ªÉ disable ƒë·ªÉ gi·∫£m cost)
  - Incremental (ch·ªâ x·ª≠ l√Ω affected entities khi update)
- ‚ö†Ô∏è **GraphRAG ƒë∆°n gi·∫£n h∆°n:** Ch·ªâ summarization, kh√¥ng c√≥ sophisticated merging
- üí° **GraphToG approach ph·ª©c t·∫°p h∆°n nh∆∞ng accurate h∆°n** cho entity disambiguation

---

### 5. Relationship Extraction

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Method** | LLM extraction c√πng v·ªõi entities | LLM extraction (separate step) |
| **Relationship attributes** | source, target, description | source, target, type, description, confidence |
| **Relationship types** | Generic "RELATED_TO" | Typed relationships (WORKS_AT, LOCATED_IN, etc.) |
| **Batch processing** | ‚úÖ | ‚úÖ `batch_extract_relationships()` |
| **Confidence scoring** | ‚ùå | ‚úÖ Confidence 0.0-1.0 |
| **Deduplication** | Merged in summarization | ‚úÖ ON MATCH update highest confidence |
| **Graph storage** | Generic edge | Neo4j typed relationship |

**Code snippet GraphToG:**
```python
# document_processor.py - Step 8
rel_results = await llm_service.batch_extract_relationships(chunk_with_entities)

for result in rel_results:
    if result["status"] == "success":
        for relationship in result["relationships"]:
            graph_service.create_relationship(
                source_entity_id=source_entity["id"],
                target_entity_id=target_entity["id"],
                relationship_type=rel_type,  # WORKS_AT, LOCATED_IN, etc.
                description=relationship.get("description", ""),
                confidence=relationship.get("confidence", 0.8),
            )
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Typed relationships ‚Üí richer semantics
  - Confidence scoring ‚Üí pruning cho ToG
  - Confidence-based deduplication
- ‚ö†Ô∏è **GraphRAG generic h∆°n:** RELATED_TO relationship with descriptions
- üí° **Trade-off:**
  - GraphRAG: ƒê∆°n gi·∫£n, LLM t·ª± do generate descriptions
  - GraphToG: Structured types, t·ªët cho graph traversal v√† pruning

---

### 6. Claim Extraction (Covariate Extraction)

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Support** | ‚úÖ Phase 2c (optional) | ‚úÖ Step 8.5 (always run) |
| **Claim attributes** | subject, object, type, status, time-bounds | subject, object, claim_type, status, description, start_date, end_date, source_text |
| **Status values** | TRUE, FALSE, SUSPECTED | TRUE, FALSE, SUSPECTED |
| **Temporal support** | ‚úÖ Time-bounds | ‚úÖ start_date, end_date (ISO-8601) |
| **Source tracking** | ‚ùå | ‚úÖ Linked to TextUnit (SOURCED_FROM) |
| **Entity linking** | ‚úÖ | ‚úÖ MAKES_CLAIM, ABOUT relationships |
| **Deduplication** | ‚ùå | ‚úÖ MERGE by claim_id (md5 hash) |
| **Occurrence tracking** | ‚ùå | ‚úÖ occurrence_count |

**Code snippet GraphToG:**
```python
# document_processor.py - Step 8.5
claims_results = await llm_service.batch_extract_claims(chunk_with_entities)

for claim in claims:
    claim_id = graph_service.create_claim_node(
        subject_entity_name=claim.get("subject", ""),
        object_entity_name=claim.get("object", ""),
        claim_type=claim.get("claim_type", "UNKNOWN"),
        status=claim.get("status", "SUSPECTED"),
        description=claim.get("description", ""),
        start_date=claim.get("start_date"),
        end_date=claim.get("end_date"),
        source_text=claim.get("source_text", ""),
    )

    # Link claim to entities and text unit
    graph_service.link_claim_to_entities(claim_id, subject, object)
    graph_service.link_claim_to_textunit(claim_id, chunk_id)
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Always-on (kh√¥ng optional)
  - Source tracking via SOURCED_FROM ‚Üí TextUnit
  - Deduplication v·ªõi occurrence tracking
  - Richer attributes (source_text, descriptions)
  - Fuzzy entity matching cho linking
- üü∞ **GraphRAG:** Temporal support t∆∞∆°ng t·ª±
- üí° **GraphToG coi claims l√† first-class citizens** trong knowledge graph

---

### 7. Community Detection

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Algorithm** | Hierarchical Leiden | Leiden (via Neo4j GDS) |
| **Hierarchy** | ‚úÖ Recursive until threshold | ‚úÖ includeIntermediateCommunities |
| **Graph projection** | Internal graph structure | Neo4j GDS graph projection |
| **Relationship types** | RELATED_TO | RELATED_TO + MENTIONED_IN (undirected) |
| **Parameters** | seed, tolerance, maxLevels | seed, tolerance, maxLevels, concurrency |
| **Community metadata** | Community ID, level | id, level, createdAt, summary (empty initially) |
| **Incremental support** | ‚ùå | ‚úÖ `detect_communities_incrementally()` |
| **Orphan cleanup** | ‚ùå | ‚úÖ Auto-remove orphaned communities |

**Code snippet GraphToG:**
```python
# community_detection_service.py
def detect_communities(self, seed=42, include_intermediate_communities=True):
    """Run Leiden algorithm via Neo4j GDS"""

    # 1. Create GDS graph projection
    gds.graph.project('entity_graph', 'Entity',
                      {'RELATED_TO': {orientation: 'UNDIRECTED'}})

    # 2. Run Leiden
    leiden_results = gds.leiden.stream('entity_graph', {
        randomSeed: seed,
        includeIntermediateCommunities: include_intermediate_communities,
        tolerance: 0.0001,
        maxLevels: 10
    })

    # 3. Store community assignments with hierarchy levels
    self._store_community_assignments(session, results)
```

**Incremental community detection (GraphToG only):**
```python
def detect_communities_incrementally(self, affected_entity_ids, seed=42):
    """Efficient incremental detection for document updates"""

    # 1. Get old communities to mark as stale
    # 2. Remove old community assignments
    # 3. Expand to 1-hop neighbors
    # 4. Create subgraph projection for affected entities
    # 5. Run Leiden on subgraph
    # 6. Update community assignments
    # 7. Clean up orphaned communities
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Incremental community detection ‚Üí efficient updates
  - Neo4j GDS integration ‚Üí native graph algorithms
  - Concurrency support (parallel processing)
  - Orphan cleanup
  - 1-hop neighbor expansion trong incremental mode
- üü∞ **T∆∞∆°ng ƒë∆∞∆°ng:** C·∫£ hai ƒë·ªÅu d√πng Hierarchical Leiden
- ‚ö†Ô∏è **GraphRAG:** Generic implementation, kh√¥ng c√≥ incremental support

---

### 8. Community Summarization

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Phase** | Phase 4 (separate phase) | Step 10 (integrated) |
| **LLM calls** | 2 passes (generate + summarize) | 1 pass (generate) |
| **Input** | Community members + relationships | Community entities + relationships + claims |
| **Output** | Executive summary + key entities/rels | Natural language summary |
| **Hierarchy handling** | Bottom-up summarization | Level-by-level summarization |
| **Storage** | Community Reports Table | Community.summary property |
| **Incremental** | ‚ùå | ‚úÖ `summarize_affected_communities()` (implied) |

**Code snippet GraphToG:**
```python
# community_summarization_service.py
def summarize_all_communities(self):
    """Generate summaries for all detected communities"""

    # 1. Get all communities
    communities = self._get_all_communities()

    for community in communities:
        # 2. Get community context (entities, relationships, claims)
        context = self._get_community_context(community["id"])

        # 3. Generate summary via LLM
        summary = await llm_service.summarize_community(
            community_id=community["id"],
            entities=context["entities"],
            relationships=context["relationships"],
            claims=context.get("claims", [])
        )

        # 4. Store summary in Community node
        self._update_community_summary(community["id"], summary)
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphRAG t·ªët h∆°n:**
  - 2-pass summarization ‚Üí executive summaries
  - Bottom-up hierarchy ‚Üí multi-level abstractions
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - Includes claims in summarization context
  - Integrated v·ªõi Neo4j (kh√¥ng c·∫ßn separate table)
  - Potentially incremental (c√≥ th·ªÉ summarize only affected)
- üí° **Different use cases:**
  - GraphRAG: Global search v·ªõi hierarchical summaries
  - GraphToG: ToG traversal context v·ªõi community-level understanding

---

### 9. Text Embeddings

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Phase** | Phase 7 (final phase) | Step 6 (integrated in pipeline) |
| **Embedded content** | TextUnits, Entity descriptions, Community reports | TextUnits (chunks) |
| **Embedding model** | User-configurable | Google Gemini text-embedding-004 |
| **Storage** | Vector store (user-defined) | PostgreSQL pgvector |
| **Deduplication** | ‚ùå | ‚úÖ Skip if embedding exists |
| **Batch processing** | ‚úÖ | ‚úÖ Batch generation |
| **Cache support** | ‚ùå | ‚úÖ Redis caching |
| **Dimension** | Model-dependent | 768 dimensions (Gemini) |

**Code snippet GraphToG:**
```python
# embedding_service.py
async def generate_and_store_embeddings(self, db, document_id, chunks):
    """Generate embeddings for chunks and store in pgvector"""

    # 1. Filter out chunks that already have embeddings
    new_chunks = self._filter_existing_embeddings(db, chunks)

    # 2. Batch generate embeddings
    embeddings = await self._batch_generate_embeddings([c["text"] for c in new_chunks])

    # 3. Store in PostgreSQL with pgvector
    for chunk, embedding in zip(new_chunks, embeddings):
        db_embedding = Embedding(
            document_id=document_id,
            chunk_id=chunk["chunk_id"],
            embedding=embedding,  # pgvector column
            text=chunk["text"]
        )
        db.add(db_embedding)

    db.commit()
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphRAG comprehensive h∆°n:**
  - Embed TextUnits + Entity descriptions + Community reports
  - Multi-level embeddings cho different retrieval strategies
- ‚úÖ **GraphToG t·ªët h∆°n:**
  - pgvector native support (SQL queries)
  - Deduplication (skip existing)
  - Redis caching
- ‚ö†Ô∏è **GraphToG thi·∫øu:** Kh√¥ng embed entity descriptions v√† community summaries

---

### 10. Graph Schema & Storage

| Ti√™u ch√≠ | Microsoft GraphRAG | GraphToG |
|---------|-------------------|----------|
| **Storage format** | Parquet files / Optional graph DB | Neo4j (required) + PostgreSQL |
| **Node types** | Entities, TextUnits, Documents, Communities, Claims | Entity, TextUnit, Document, Community, Claim |
| **Relationship types** | Generic RELATED_TO | Typed: RELATED_TO, MENTIONED_IN, PART_OF, IN_COMMUNITY, MAKES_CLAIM, ABOUT, SOURCED_FROM |
| **Constraints** | N/A (file-based) | Entity (name+type) UNIQUE, Document name UNIQUE, TextUnit id UNIQUE, Community id UNIQUE, Claim id UNIQUE |
| **Indexes** | N/A | 15+ indexes cho performance (entity name, type, document_id, mention_count, etc.) |
| **ToG optimization** | ‚ùå | ‚úÖ Indexes cho entity name lookup, relation type, confidence, mention_count |

**GraphToG Schema (graph_service.py):**
```cypher
// Constraints
CREATE CONSTRAINT entity_name_type IF NOT EXISTS
FOR (e:Entity) REQUIRE (e.name, e.type) IS UNIQUE

CREATE CONSTRAINT document_name IF NOT EXISTS
FOR (d:Document) REQUIRE d.name IS UNIQUE

// ToG-specific indexes
CREATE INDEX entity_name_lookup IF NOT EXISTS
FOR (e:Entity) ON (e.name)

CREATE INDEX entity_mention_count IF NOT EXISTS
FOR (e:Entity) ON (e.mention_count)

CREATE INDEX relation_type IF NOT EXISTS
FOR ()-[r:RELATES_TO]-() ON (r.type)
```

**ƒê√°nh gi√°:**
- ‚úÖ **GraphToG v∆∞·ª£t tr·ªôi:**
  - Native graph database (Neo4j) ‚Üí efficient traversal
  - Constraints ƒë·∫£m b·∫£o data integrity
  - Extensive indexing cho ToG performance
  - Typed relationships ‚Üí semantic richness
- ‚ö†Ô∏è **GraphRAG flexible h∆°n:**
  - File-based ‚Üí kh√¥ng c·∫ßn graph DB infrastructure
  - C√≥ th·ªÉ integrate v·ªõi b·∫•t k·ª≥ graph DB n√†o
- üí° **Trade-off:** GraphRAG portability vs GraphToG performance

---

## T·ªïng K·∫øt So S√°nh

### ƒêi·ªÉm M·∫°nh C·ªßa Microsoft GraphRAG

1. **Simplicity & Portability**
   - File-based storage (Parquet) ‚Üí kh√¥ng c·∫ßn infrastructure ph·ª©c t·∫°p
   - C√≥ th·ªÉ ch·∫°y tr√™n b·∫•t k·ª≥ m√¥i tr∆∞·ªùng n√†o
   - Easy to deploy v√† scale horizontally

2. **Hierarchical Community Summarization**
   - 2-pass summarization (generate + summarize)
   - Bottom-up hierarchy ‚Üí multi-level abstractions
   - T·ªëi ∆∞u cho global search queries

3. **Comprehensive Embeddings**
   - Embed TextUnits + Entities + Community reports
   - Multi-level retrieval strategies

4. **Mature Ecosystem**
   - Well-documented
   - Active community
   - Integration v·ªõi nhi·ªÅu tools (LlamaIndex, LangChain, etc.)

### ƒêi·ªÉm M·∫°nh C·ªßa GraphToG

1. **Incremental Update Support** ‚≠ê‚≠ê‚≠ê
   - Content hash tracking
   - Change detection
   - Incremental entity resolution
   - Incremental community detection
   - **‚Üí Production-ready cho systems c·∫ßn update th∆∞·ªùng xuy√™n**

2. **Advanced Entity Resolution** ‚≠ê‚≠ê‚≠ê
   - 3-stage pipeline: Fuzzy matching ‚Üí LLM verification ‚Üí Merge
   - Configurable thresholds
   - Alias tracking
   - Mention count tracking
   - **‚Üí Higher quality entity disambiguation**

3. **Rich Graph Semantics** ‚≠ê‚≠ê
   - Typed relationships (not just RELATED_TO)
   - Confidence scoring
   - Claims as first-class nodes
   - Source tracking (claims ‚Üí text units)
   - **‚Üí Richer knowledge representation**

4. **Neo4j Native Integration** ‚≠ê‚≠ê‚≠ê
   - Native graph algorithms (Leiden via GDS)
   - Constraints & indexes
   - Efficient graph traversal
   - ToG-optimized indexes
   - **‚Üí Best performance cho multi-hop reasoning**

5. **Claims Integration** ‚≠ê‚≠ê
   - Always-on claim extraction
   - Occurrence tracking
   - Temporal support
   - Fuzzy entity linking
   - **‚Üí Better factual reasoning**

6. **Caching & Optimization** ‚≠ê
   - Redis caching
   - pgvector deduplication
   - Batch processing
   - Concurrency support

### ƒêi·ªÉm Y·∫øu C·ªßa GraphToG

1. **Infrastructure Complexity**
   - Requires Neo4j + PostgreSQL + Redis
   - Harder to deploy v√† maintain
   - Higher operational cost

2. **Limited File Format Support**
   - Ch·ªâ h·ªó tr·ª£ Markdown (.md)
   - GraphRAG h·ªó tr·ª£ CSV, .txt, v√† extensible

3. **Single-pass Community Summarization**
   - Kh√¥ng c√≥ hierarchical summarization nh∆∞ GraphRAG
   - C√≥ th·ªÉ k√©m hi·ªáu qu·∫£ cho global search

4. **Missing Multi-level Embeddings**
   - Ch·ªâ embed text chunks
   - Kh√¥ng embed entity descriptions v√† community summaries

---

## Alignment v·ªõi Microsoft GraphRAG

### ‚úÖ ƒê√£ Gi·ªëng (High Alignment)

| Feature | Implementation |
|---------|----------------|
| **Text Chunking** | Token-based v·ªõi tiktoken, configurable size |
| **Entity Extraction** | LLM-based v·ªõi batch processing |
| **Relationship Extraction** | LLM-based extraction |
| **Claim Extraction** | Subject, object, type, status, temporal bounds |
| **Community Detection** | Hierarchical Leiden algorithm |
| **Community Summarization** | LLM-generated summaries |
| **Text Embeddings** | Vector embeddings for chunks |

### ‚ö†Ô∏è Kh√°c Bi·ªát (Partial Alignment)

| Feature | GraphRAG | GraphToG | Impact |
|---------|----------|----------|--------|
| **Overlap trong chunking** | ‚ùå | ‚úÖ 500 tokens | T·ªët cho context continuity |
| **Entity resolution** | Basic summarization | Advanced 3-stage | T·ªët h∆°n cho disambiguation |
| **Relationship types** | Generic RELATED_TO | Typed relationships | Semantic richness vs simplicity |
| **Graph storage** | File-based | Neo4j required | Portability vs performance |
| **Incremental updates** | ‚ùå | ‚úÖ Full support | Production-readiness |

### ‚ùå Thi·∫øu So V·ªõi GraphRAG

1. **Multi-level embeddings**
   - GraphRAG: TextUnits + Entities + Communities
   - GraphToG: Ch·ªâ TextUnits
   - **Impact:** GraphToG c√≥ th·ªÉ k√©m hi·ªáu qu·∫£ cho entity-based retrieval

2. **2-pass community summarization**
   - GraphRAG: Generate ‚Üí Summarize ‚Üí Executive summaries
   - GraphToG: Single-pass generation
   - **Impact:** GraphToG summaries c√≥ th·ªÉ verbose h∆°n

3. **File format flexibility**
   - GraphRAG: CSV, .txt, extensible
   - GraphToG: Markdown only
   - **Impact:** Limited use cases

### ‚≠ê V∆∞·ª£t Tr·ªôi H∆°n GraphRAG

1. **Incremental processing** ‚Üí Production-ready
2. **Advanced entity resolution** ‚Üí Higher quality
3. **Neo4j native integration** ‚Üí Best performance cho graph queries
4. **Claims as first-class nodes** ‚Üí Better reasoning
5. **Source tracking** ‚Üí Traceability

---

## K·∫øt Lu·∫≠n

### GraphToG c√≥ gi·ªëng v·ªõi GraphRAG kh√¥ng?

**Tr·∫£ l·ªùi: Gi·ªëng 70-80%, nh∆∞ng c√≥ nh·ªØng c·∫£i ti·∫øn quan tr·ªçng**

### Chi Ti·∫øt:

#### Core Pipeline: ‚úÖ Gi·ªëng (90%)
- Text chunking ‚Üí Entity extraction ‚Üí Relationship extraction ‚Üí Community detection ‚Üí Summarization
- C·∫£ hai ƒë·ªÅu d√πng LLM-based extraction v·ªõi Leiden algorithm

#### Implementation Details: ‚ö†Ô∏è Kh√°c Bi·ªát (60%)
- **Storage:** File-based vs Neo4j (fundamental difference)
- **Incremental updates:** GraphToG c√≥, GraphRAG kh√¥ng
- **Entity resolution:** GraphToG sophisticated h∆°n
- **Schema:** GraphToG typed relationships, GraphRAG generic

#### Production Readiness: ‚≠ê GraphToG T·ªët H∆°n
- Incremental updates ‚Üí kh√¥ng c·∫ßn reindex to√†n b·ªô
- Change detection ‚Üí efficient resource usage
- Neo4j optimization ‚Üí fast multi-hop queries
- Claims integration ‚Üí better factual reasoning

### Recommendations

#### N·∫øu Mu·ªën Alignment 100% V·ªõi GraphRAG:

1. **Add multi-level embeddings:**
   ```python
   # Embed entity descriptions
   await embedding_service.generate_entity_embeddings(entities)

   # Embed community summaries
   await embedding_service.generate_community_embeddings(communities)
   ```

2. **Add 2-pass community summarization:**
   ```python
   # Pass 1: Generate detailed reports
   detailed_reports = await summarize_communities(communities)

   # Pass 2: Summarize to executive summaries
   exec_summaries = await summarize_reports(detailed_reports)
   ```

3. **Support more file formats:**
   ```python
   # Add CSV, TXT parsers
   if file_ext == "csv":
       return DocumentProcessor.parse_csv(file_path)
   elif file_ext == "txt":
       return DocumentProcessor.parse_txt(file_path)
   ```

#### N·∫øu Gi·ªØ Nguy√™n GraphToG Philosophy:

**Keep incremental updates v√† advanced entity resolution** ‚Üí ƒê√¢y l√† competitive advantages

**Maintain Neo4j native integration** ‚Üí Best cho ToG multi-hop reasoning

**Consider adding:**
- Multi-level embeddings (entity + community)
- File format flexibility (CSV, TXT)
- Optional file-based export (for portability)

---

## Appendix: Code Comparison

### GraphRAG Dataflow (Conceptual)
```
Documents ‚Üí compose_text_units ‚Üí TextUnits
  ‚Üì
TextUnits ‚Üí entity_extract ‚Üí Entities + Relationships
  ‚Üì
Entities ‚Üí entity_summarize ‚Üí Merged Entities
  ‚Üì
Relationships ‚Üí relationship_summarize ‚Üí Merged Relationships
  ‚Üì
TextUnits ‚Üí claim_extract ‚Üí Claims [optional]
  ‚Üì
Graph ‚Üí leiden_community_detection ‚Üí Communities
  ‚Üì
Communities ‚Üí community_summarize ‚Üí Community Reports
  ‚Üì
Community Reports ‚Üí summarize_reports ‚Üí Executive Summaries
  ‚Üì
All ‚Üí text_embed ‚Üí Vector Store
```

### GraphToG Pipeline (Actual Implementation)
```
Document (MD) ‚Üí compute_content_hash ‚Üí Change Detection
  ‚Üì
[If changed or new]
  ‚Üì
parse_md ‚Üí Full Text
  ‚Üì
create_chunks (with overlap) ‚Üí TextUnits
  ‚Üì
batch_extract_entities ‚Üí Entities
  ‚Üì
[Optional] find_duplicate_entity_pairs ‚Üí Entity Resolution
  ‚Üì           ‚Üì [fuzzy match]
  ‚Üì           ‚Üì [LLM verification]
  ‚Üì           ‚Üì merge_entities
  ‚Üì
batch_extract_relationships ‚Üí Typed Relationships
  ‚Üì
batch_extract_claims ‚Üí Claims (always)
  ‚Üì
detect_communities (Leiden via Neo4j GDS) ‚Üí Communities
  ‚Üì
[Optional] detect_communities_incrementally [if update]
  ‚Üì
summarize_all_communities ‚Üí Community Summaries
  ‚Üì
generate_and_store_embeddings ‚Üí pgvector (TextUnits only)
  ‚Üì
[Optional] Cache in Redis
```

### Key Architectural Difference:
- **GraphRAG:** Linear pipeline v·ªõi clear phases, file-based
- **GraphToG:** Integrated pipeline v·ªõi Neo4j, incremental-first design

---

**T√°c gi·∫£:** Claude Code
**Codebase:** GraphToG (F:\khoaluan\graphtog)
**Reference:** Microsoft GraphRAG (https://github.com/microsoft/graphrag)
